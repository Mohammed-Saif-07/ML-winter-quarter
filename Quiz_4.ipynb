{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohammed-Saif-07/ML-winter-quarter/blob/main/Quiz_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab-Based Quiz 4  \n",
        "# Time: 1 hour\n",
        "## Comparing Individual Models vs Ensemble Methods  \n",
        "### Dataset: Breast Cancer Wisconsin (Diagnostic)\n",
        "\n",
        "\n",
        "## Objective\n",
        "\n",
        "In this lab, you will:\n",
        "\n",
        "1. Train and evaluate the following classifiers individually:\n",
        "   - Decision Tree\n",
        "   - Naive Bayes\n",
        "   - K-Nearest Neighbors (KNN)\n",
        "   - Logistic Regression\n",
        "   - SGD Classifier\n",
        "\n",
        "2. Build ensemble models using:\n",
        "   - Hard Voting\n",
        "   - Soft Voting\n",
        "   - Bagging\n",
        "   - Random Forest\n",
        "   - AdaBoost\n",
        "\n",
        "3. Compare all models using appropriate evaluation metrics.\n",
        "\n",
        "4. Decide which metric best represents performance in this case study and justify your reasoning.\n",
        "\n",
        "5. Write your own summary explaining your findings.\n",
        "\n",
        "**Important**:\n",
        "- Do NOT hard-code results.\n",
        "- Do NOT use Gemini or any LLM model to do this for you.\n",
        "- All answers must be written in your own words.\n",
        "- Replace each TODO with working code."
      ],
      "metadata": {
        "id": "3OqaPZBHnykr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 – Load and Explore the Dataset\n",
        "\n",
        "The Breast Cancer Wisconsin dataset is a binary classification dataset."
      ],
      "metadata": {
        "id": "8KE3O-LvoVCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "breast_cancer = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)\n",
        "\n",
        "df['target'] = breast_cancer.target\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "51oGg3DdocyE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "7b2c3ff8-5a39-4722-9701-3826491dafcb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                 0.07871  ...          17.33           184.60      2019.0   \n",
              "1                 0.05667  ...          23.41           158.80      1956.0   \n",
              "2                 0.05999  ...          25.53           152.50      1709.0   \n",
              "3                 0.09744  ...          26.50            98.87       567.7   \n",
              "4                 0.05883  ...          16.67           152.20      1575.0   \n",
              "\n",
              "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   worst symmetry  worst fractal dimension  target  \n",
              "0          0.4601                  0.11890       0  \n",
              "1          0.2750                  0.08902       0  \n",
              "2          0.3613                  0.08758       0  \n",
              "3          0.6638                  0.17300       0  \n",
              "4          0.2364                  0.07678       0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce4236bb-81d5-4a94-8bef-3f337befcb87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce4236bb-81d5-4a94-8bef-3f337befcb87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce4236bb-81d5-4a94-8bef-3f337befcb87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce4236bb-81d5-4a94-8bef-3f337befcb87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Exploration\n",
        "\n",
        "1. How many samples and features are there?\n",
        "2. What are the target classes?\n",
        "3. Is the dataset balanced?"
      ],
      "metadata": {
        "id": "zDMxAhOHoizL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset shape:\", df.shape)\n",
        "\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['target'].value_counts())\n",
        "\n",
        "\n",
        "print(\"\\nClass percentage:\")\n",
        "print(df['target'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "4Qaah5jVonYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2dc378-f143-4427-ffec-8d11940197c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (569, 31)\n",
            "\n",
            "Class distribution:\n",
            "target\n",
            "1    357\n",
            "0    212\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class percentage:\n",
            "target\n",
            "1    62.741652\n",
            "0    37.258348\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write your answers below:\n",
        "\n",
        "- Number of samples:\n",
        "- Number of features:\n",
        "- Class distribution:\n",
        "- Is the dataset balanced?"
      ],
      "metadata": {
        "id": "yJ-e699losPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of samples: 569\n",
        "\n",
        "Number of features: 30\n",
        "\n",
        "Class distribution: 357 malignant (0), 212 benign (1) (your output may show reversed order depending on labeling)\n",
        "\n",
        "Is the dataset balanced?\n",
        "\n",
        "The dataset is slightly imbalanced but not severely. One class has more samples than the other."
      ],
      "metadata": {
        "id": "832ghv2D5Qo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 – Train/Test Split and Scaling"
      ],
      "metadata": {
        "id": "AUd_SPnCo0FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "#(80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "b63tsDp1orJs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In 2–3 sentences:\n",
        "Why is scaling necessary for some models but not for others?"
      ],
      "metadata": {
        "id": "FAMG9EqZpIUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 – Train Individual Models\n",
        "\n",
        "For EACH model:\n",
        "\n",
        "* Train\n",
        "\n",
        "* Predict\n",
        "\n",
        "* Compute:\n",
        "\n",
        "  * Accuracy\n",
        "\n",
        "  * Precision\n",
        "\n",
        "  * Recall\n",
        "\n",
        "  * F1-score\n",
        "\n",
        "  * Confusion Matrix\n",
        "\n",
        "Store results for later comparison"
      ],
      "metadata": {
        "id": "-7_hN2ojpS_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "results = {}\n",
        "\n",
        "def evaluate_model(name, model, X_train, X_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"Confusion Matrix\": confusion_matrix(y_test, y_pred)\n",
        "    }"
      ],
      "metadata": {
        "id": "izGttu1Dp43h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "evaluate_model(\"Decision Tree\", dt, X_train, X_test)"
      ],
      "metadata": {
        "id": "zNJxgaMlp7tm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "evaluate_model(\"Naive Bayes\", nb, X_train, X_test)"
      ],
      "metadata": {
        "id": "Uu98rs6_p-er"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "evaluate_model(\"KNN\", knn, X_train_scaled, X_test_scaled)"
      ],
      "metadata": {
        "id": "RR9kwj-Kp-iI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=5000)\n",
        "evaluate_model(\"Logistic Regression\", lr, X_train_scaled, X_test_scaled)"
      ],
      "metadata": {
        "id": "IjxJCbhvp-ly"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = SGDClassifier(random_state=42)\n",
        "evaluate_model(\"SGD\", sgd, X_train_scaled, X_test_scaled)"
      ],
      "metadata": {
        "id": "38dxMCnv5qWw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling is necessary for models like KNN, Logistic Regression, and SGD because they rely on distance calculations or gradient optimization. If features are not scaled, variables with larger magnitudes dominate the model. Tree-based models like Decision Trees do not require scaling because they split based on feature thresholds rather than distances."
      ],
      "metadata": {
        "id": "oLbRnuxW5sn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4 – Voting Classifier"
      ],
      "metadata": {
        "id": "S_3JuSdqqD1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Hard Voting\n",
        "hard_voting = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', lr),\n",
        "        ('knn', knn),\n",
        "        ('dt', dt)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "evaluate_model(\"Hard Voting\", hard_voting, X_train_scaled, X_test_scaled)\n",
        "\n",
        "# Soft Voting\n",
        "soft_voting = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', lr),\n",
        "        ('knn', knn),\n",
        "        ('nb', nb)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "evaluate_model(\"Soft Voting\", soft_voting, X_train_scaled, X_test_scaled)"
      ],
      "metadata": {
        "id": "zGipQHI5qMVb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hard voting selects the class predicted by the majority of classifiers. Soft voting averages the predicted probabilities from each classifier and chooses the class with the highest probability. Soft voting usually performs better because it considers confidence levels."
      ],
      "metadata": {
        "id": "miu0OKKJ5xnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5 – Bagging and Boosting"
      ],
      "metadata": {
        "id": "NiLq5HP0qXEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "bagging = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "evaluate_model(\"Bagging\", bagging, X_train, X_test)"
      ],
      "metadata": {
        "id": "RR6zwOIgqMq4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "evaluate_model(\"Random Forest\", rf, X_train, X_test)"
      ],
      "metadata": {
        "id": "5EPacjf2qcua"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "evaluate_model(\"AdaBoost\", ada, X_train, X_test)"
      ],
      "metadata": {
        "id": "Kx9K9GnvqcyM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6 – Model Comparison"
      ],
      "metadata": {
        "id": "vasxui5CqkcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = pd.DataFrame(results).T\n",
        "comparison_df = comparison_df.drop(columns=[\"Confusion Matrix\"])\n",
        "\n",
        "comparison_df = comparison_df.sort_values(by=\"F1-score\", ascending=False)\n",
        "\n",
        "comparison_df"
      ],
      "metadata": {
        "id": "mEgyysRtqc1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "990dcc08-f14a-4ce8-a125-dbb6aec7467d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Accuracy Precision    Recall  F1-score\n",
              "Naive Bayes          0.973684  0.959459       1.0   0.97931\n",
              "Logistic Regression  0.973684  0.972222  0.985915  0.979021\n",
              "Hard Voting          0.973684  0.972222  0.985915  0.979021\n",
              "Soft Voting          0.973684  0.972222  0.985915  0.979021\n",
              "Random Forest        0.964912  0.958904  0.985915  0.972222\n",
              "AdaBoost             0.964912  0.958904  0.985915  0.972222\n",
              "SGD                  0.964912  0.985507  0.957746  0.971429\n",
              "Bagging               0.95614  0.958333  0.971831  0.965035\n",
              "Decision Tree        0.947368  0.957746  0.957746  0.957746\n",
              "KNN                  0.947368  0.957746  0.957746  0.957746"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba0496df-2aeb-4334-b739-950aba577503\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.97931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.985915</td>\n",
              "      <td>0.979021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hard Voting</th>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.985915</td>\n",
              "      <td>0.979021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soft Voting</th>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.985915</td>\n",
              "      <td>0.979021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.958904</td>\n",
              "      <td>0.985915</td>\n",
              "      <td>0.972222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.958904</td>\n",
              "      <td>0.985915</td>\n",
              "      <td>0.972222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD</th>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>0.957746</td>\n",
              "      <td>0.971429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>0.95614</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.971831</td>\n",
              "      <td>0.965035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.957746</td>\n",
              "      <td>0.957746</td>\n",
              "      <td>0.957746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.957746</td>\n",
              "      <td>0.957746</td>\n",
              "      <td>0.957746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba0496df-2aeb-4334-b739-950aba577503')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba0496df-2aeb-4334-b739-950aba577503 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba0496df-2aeb-4334-b739-950aba577503');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_ab4234a4-a9d8-450e-b107-b0c763c8584d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ab4234a4-a9d8-450e-b107-b0c763c8584d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.9473684210526315,\n        \"max\": 0.9736842105263158,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9649122807017544,\n          0.9473684210526315,\n          0.9736842105263158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.9577464788732394,\n        \"max\": 0.9855072463768116,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9594594594594594,\n          0.9722222222222222,\n          0.9577464788732394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.9577464788732394,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9859154929577465,\n          0.971830985915493,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-score\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.9577464788732394,\n        \"max\": 0.9793103448275862,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9793103448275862,\n          0.9790209790209791,\n          0.9577464788732394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this was not asked\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"Confusion Matrix for {model_name}\")\n",
        "    print(metrics[\"Confusion Matrix\"])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh3F_5abB08H",
        "outputId": "923fb045-83e7-442d-df78-fd3622dddc43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Decision Tree\n",
            "[[40  3]\n",
            " [ 3 68]]\n",
            "\n",
            "Confusion Matrix for Naive Bayes\n",
            "[[40  3]\n",
            " [ 0 71]]\n",
            "\n",
            "Confusion Matrix for KNN\n",
            "[[40  3]\n",
            " [ 3 68]]\n",
            "\n",
            "Confusion Matrix for Logistic Regression\n",
            "[[41  2]\n",
            " [ 1 70]]\n",
            "\n",
            "Confusion Matrix for SGD\n",
            "[[42  1]\n",
            " [ 3 68]]\n",
            "\n",
            "Confusion Matrix for Hard Voting\n",
            "[[41  2]\n",
            " [ 1 70]]\n",
            "\n",
            "Confusion Matrix for Soft Voting\n",
            "[[41  2]\n",
            " [ 1 70]]\n",
            "\n",
            "Confusion Matrix for Bagging\n",
            "[[40  3]\n",
            " [ 2 69]]\n",
            "\n",
            "Confusion Matrix for Random Forest\n",
            "[[40  3]\n",
            " [ 1 70]]\n",
            "\n",
            "Confusion Matrix for AdaBoost\n",
            "[[40  3]\n",
            " [ 1 70]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 7 – Metric Selection and Interpretation"
      ],
      "metadata": {
        "id": "Tkyoes0_qq_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the following:\n",
        "\n",
        "1. Which model achieved the highest accuracy?\n",
        "\n",
        "  ans - Naive Bayes\n",
        "\n",
        "2. Which model achieved the highest recall?\n",
        "\n",
        "  ans - Naive Bayes\n",
        "  \n",
        "3. Which model achieved the highest F1-score?\n",
        "\n",
        "Naive Bayes\n",
        "\n",
        "The most important metric in this case is Recall.\n",
        "\n",
        "In medical diagnosis, missing a cancer case (false negative) can be life descion. A high recall ensures that most patients who actually have cancer are correctly identified. Even if precision is slightly lower, it is safer to flag more cases than to miss someone who truly has the disease.\n",
        "\n",
        "If a model has high accuracy but low recall, it means it performs well overall but fails to detect many actual cancer cases. In this medical context, that would be very dangerous because patients with cancer might be incorrectly classified as healthy and not receive timely treatment."
      ],
      "metadata": {
        "id": "HI8vc74iqxEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 8 – Final Reflection (Required)"
      ],
      "metadata": {
        "id": "YACDetjZq2b4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Reflection (1-2 paragraphs)\n",
        "\n",
        "Write a short summary in your own words explaining:\n",
        "\n",
        "- What you observed when comparing individual models vs ensemble models.\n",
        "- Whether ensemble methods improved performance.\n",
        "- Which model you would choose for real-world deployment.\n",
        "- Which metric best represents performance in this case study and why.\n",
        "- Any surprising findings.\n",
        "\n",
        "\n",
        "**My summary**\n",
        "\n",
        "When comparing the individual models to the ensemble models, I observed that several ensemble methods performed very well, but they did not drastically outperform the best individual model. In my results, Naive Bayes achieved the highest F1-score, highest recall, and tied for highest accuracy. While ensemble methods like Random Forest, AdaBoost, and Voting classifiers performed strongly and were very consistent, they did not significantly exceed the performance of the top individual model. This shows that although ensemble methods often improve stability and generalization, a well-suited single model can sometimes perform just as well on a structured dataset like this one.\n",
        "\n",
        "For real-world deployment, I would choose Naive Bayes in this case because it achieved perfect recall (1.00), meaning it correctly identified all cancer cases in the test set. In medical diagnosis, recall is the most important metric because missing a cancer case (false negative) can have serious consequences. Accuracy alone is not enough, since a model can appear accurate while still failing to detect actual positive cases. One surprising finding was that ensemble methods did not clearly outperform Naive Bayes, even though ensembles are generally expected to perform better. This highlights that model performance depends heavily on the dataset and problem context."
      ],
      "metadata": {
        "id": "S6-zCYRqq5-U"
      }
    }
  ]
}